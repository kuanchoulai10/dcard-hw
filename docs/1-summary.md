# 摘要
```shell
$ tree
.
├── eda_evaluation.ipynb：用來匯出圖示的筆記本
├── outputs
│   ├── best_model.h5：訓練過後得到的最佳模型
│   ├── cv_results.csv：交叉驗證結果
│   └── output.csv：公開資料集的預測結果
├── predict.py：預測用的 utility
├── preprocessing.py：兩個 utilities 共用的函式，包括資料庫連線、前處理等
├── requirement.txt：Python 所需套件及其版本清單
└── training.py：訓練用的 utility
```

訓練集的文章涵蓋日期範圍從 2019 年的 4 月 1 日開始，持續到同年 10 月底，共 7 個月左右。總篇數有 79.3 萬篇左右，其中約有 2.32% 的文章是熱門文章，約莫是 1.8 萬篇。透過探索性資料分析，我們發現變數之間的相關性普遍偏高，且在什麼時間點發文確實會影響熱門文章的比例，以及發文 36 小時內的愛心總數。

我們決定以「不考慮序列資訊」的「二元分類模型」作為我們的主要內容，並且聚焦在不平衡資料集的處理、tree-based 集成模型和後續討論上。在訓練過程中，主要可分為三個階段：
1. 重抽樣（resampling）
2. 欄位轉換（column transformation）
3. 分類（classification）

經由嘗試，我們決定省略了「特徵轉換」階段，最終共有 108 種組合需要嘗試，透過 `GridSearchCV` 找尋最佳組合，設定 `cv=3`。

以 f1-score 作為模型衡量指標，最佳模型是不做任何重抽樣的 `AdaBoostClassifier`，內部共有 100 棵樹深限制為 2 層的決策樹，交叉驗證的平均 f1-score 是 0.56。其在公開測試集的 f1-score 則是 0.53。實驗過程有幾個結論：
- 不同的重抽樣策略確實會對 f1-score 造成影響。
- 重抽樣策略確實能捕捉到實際上為熱門的文章，但取而代之的就是我們不太能相信它所預測的熱門文章，實際上確實也是熱門文章。
- 在「SMOTE 重抽樣策略」以及「不做任何重抽樣」的情況底下，不同的分類器選擇並不會造成 f1-score 大幅度的變化。
- 不同的分類器選擇對 f1-score 造成的影響並不大。

最後我們也討論了幾個可能的未來方向，包括考慮其它重抽樣技術、其它衡量指標、序列資訊等。
